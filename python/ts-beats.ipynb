{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 7 N-BEATS layer\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class NBeatsBlock(tf.keras.layers.Layer):\n",
    "  def __init__(self, \n",
    "               input_size: int,\n",
    "               theta_size: int,\n",
    "               horizon: int,\n",
    "               n_neurons: int,\n",
    "               n_layers: int,\n",
    "               **kwargs): \n",
    "    super().__init__(**kwargs)\n",
    "    self.input_size = input_size\n",
    "    self.theta_size = theta_size\n",
    "    self.horizon = horizon\n",
    "    self.n_neurons = n_neurons\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    # Block contains stack of 4 fully connected layers each has ReLU activation\n",
    "    self.hidden = [tf.keras.layers.Dense(n_neurons, activation=\"relu\") for _ in range(n_layers)]\n",
    "    # Output of block is a theta layer with linear activation\n",
    "    self.theta_layer = tf.keras.layers.Dense(theta_size, activation=\"linear\", name=\"theta\")\n",
    "\n",
    "  def call(self, inputs): # the call method is what runs when the layer is called \n",
    "    x = inputs \n",
    "    for layer in self.hidden: # pass inputs through each hidden layer \n",
    "      x = layer(x)\n",
    "    theta = self.theta_layer(x) \n",
    "    # Output the backcast and forecast from theta\n",
    "    backcast, forecast = theta[:, :self.input_size], theta[:, -self.horizon:]\n",
    "    return backcast, forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>123.65499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>125.45500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>108.58483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>118.67466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>121.33866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Price\n",
       "Date                 \n",
       "2013-10-01  123.65499\n",
       "2013-10-02  125.45500\n",
       "2013-10-03  108.58483\n",
       "2013-10-04  118.67466\n",
       "2013-10-05  121.33866"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HORIZON = 1 # how far to predict forward\n",
    "WINDOW_SIZE = 7 # how far to lookback\n",
    "\n",
    "df = pd.read_csv(\"BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\", \n",
    "                 parse_dates=[\"Date\"], \n",
    "                 index_col=[\"Date\"]) \n",
    "\n",
    "bitcoin_prices = pd.DataFrame(df[\"Closing Price (USD)\"]).rename(columns={\"Closing Price (USD)\": \"Price\"})\n",
    "bitcoin_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Price+1</th>\n",
       "      <th>Price+2</th>\n",
       "      <th>Price+3</th>\n",
       "      <th>Price+4</th>\n",
       "      <th>Price+5</th>\n",
       "      <th>Price+6</th>\n",
       "      <th>Price+7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-08</th>\n",
       "      <td>123.03300</td>\n",
       "      <td>121.79500</td>\n",
       "      <td>120.65533</td>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-09</th>\n",
       "      <td>124.04900</td>\n",
       "      <td>123.03300</td>\n",
       "      <td>121.79500</td>\n",
       "      <td>120.65533</td>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-10</th>\n",
       "      <td>125.96116</td>\n",
       "      <td>124.04900</td>\n",
       "      <td>123.03300</td>\n",
       "      <td>121.79500</td>\n",
       "      <td>120.65533</td>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-11</th>\n",
       "      <td>125.27966</td>\n",
       "      <td>125.96116</td>\n",
       "      <td>124.04900</td>\n",
       "      <td>123.03300</td>\n",
       "      <td>121.79500</td>\n",
       "      <td>120.65533</td>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-12</th>\n",
       "      <td>125.92750</td>\n",
       "      <td>125.27966</td>\n",
       "      <td>125.96116</td>\n",
       "      <td>124.04900</td>\n",
       "      <td>123.03300</td>\n",
       "      <td>121.79500</td>\n",
       "      <td>120.65533</td>\n",
       "      <td>121.33866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Price    Price+1    Price+2    Price+3    Price+4    Price+5  \\\n",
       "Date                                                                           \n",
       "2013-10-08  123.03300  121.79500  120.65533  121.33866  118.67466  108.58483   \n",
       "2013-10-09  124.04900  123.03300  121.79500  120.65533  121.33866  118.67466   \n",
       "2013-10-10  125.96116  124.04900  123.03300  121.79500  120.65533  121.33866   \n",
       "2013-10-11  125.27966  125.96116  124.04900  123.03300  121.79500  120.65533   \n",
       "2013-10-12  125.92750  125.27966  125.96116  124.04900  123.03300  121.79500   \n",
       "\n",
       "              Price+6    Price+7  \n",
       "Date                              \n",
       "2013-10-08  125.45500  123.65499  \n",
       "2013-10-09  108.58483  125.45500  \n",
       "2013-10-10  118.67466  108.58483  \n",
       "2013-10-11  121.33866  118.67466  \n",
       "2013-10-12  120.65533  121.33866  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices_nbeats = bitcoin_prices.copy()\n",
    "for i in range(WINDOW_SIZE):\n",
    "  bitcoin_prices_nbeats[f\"Price+{i+1}\"] = bitcoin_prices_nbeats[\"Price\"].shift(periods=i+1)\n",
    "bitcoin_prices_nbeats.dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2224, 2224, 556, 556)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make features and labels\n",
    "X = bitcoin_prices_nbeats.dropna().drop(\"Price\", axis=1)\n",
    "y = bitcoin_prices_nbeats.dropna()[\"Price\"]\n",
    "\n",
    "# Make train and test sets\n",
    "split_size = int(len(X) * 0.8)\n",
    "X_train, y_train = X[:split_size], y[:split_size]\n",
    "X_test, y_test = X[split_size:], y[split_size:]\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 22:10:10.943459: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset element_spec=(TensorSpec(shape=(None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>,\n",
       " <PrefetchDataset element_spec=(TensorSpec(shape=(None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Turn train and test arrays into tensor Datasets\n",
    "train_features_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "train_labels_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "\n",
    "test_features_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
    "test_labels_dataset = tf.data.Dataset.from_tensor_slices(y_test)\n",
    "\n",
    "# 2. Combine features & labels\n",
    "train_dataset = tf.data.Dataset.zip((train_features_dataset, train_labels_dataset))\n",
    "test_dataset = tf.data.Dataset.zip((test_features_dataset, test_labels_dataset))\n",
    "\n",
    "# 3. Batch and prefetch for optimal performance\n",
    "BATCH_SIZE = 1024 # taken from Appendix D in N-BEATS paper\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_EPOCHS = 5000 \n",
    "N_NEURONS = 512 \n",
    "N_LAYERS = 4\n",
    "N_STACKS = 30\n",
    "\n",
    "INPUT_SIZE = WINDOW_SIZE * HORIZON \n",
    "THETA_SIZE = INPUT_SIZE + HORIZON\n",
    "\n",
    "INPUT_SIZE, THETA_SIZE\n",
    "\n",
    "INPUT_SIZE = WINDOW_SIZE * HORIZON \n",
    "THETA_SIZE = INPUT_SIZE + HORIZON\n",
    "INPUT_SIZE, THETA_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 468: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 568: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "CPU times: user 1h 23min 4s, sys: 5min 38s, total: 1h 28min 43s\n",
      "Wall time: 29min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14c12c790>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Setup N-BEATS Block layer\n",
    "nbeats_block_layer = NBeatsBlock(input_size=INPUT_SIZE,\n",
    "                                 theta_size=THETA_SIZE,\n",
    "                                 horizon=HORIZON,\n",
    "                                 n_neurons=N_NEURONS,\n",
    "                                 n_layers=N_LAYERS,\n",
    "                                 name=\"InitialBlock\")\n",
    "\n",
    "# 2. Create input to stacks\n",
    "stack_input = layers.Input(shape=(INPUT_SIZE), name=\"stack_input\")\n",
    "\n",
    "# 3. Create initial backcast and forecast input (backwards predictions are referred to as residuals in the paper)\n",
    "backcast, forecast = nbeats_block_layer(stack_input)\n",
    "# Add in subtraction residual link, thank you to: https://github.com/mrdbourke/tensorflow-deep-learning/discussions/174 \n",
    "residuals = layers.subtract([stack_input, backcast], name=f\"subtract_00\") \n",
    "\n",
    "# 4. Create stacks of blocks\n",
    "for i, _ in enumerate(range(N_STACKS-1)): # first stack is already creted in (3)\n",
    "\n",
    "  # 5. Use the NBeatsBlock to calculate the backcast as well as block forecast\n",
    "  backcast, block_forecast = NBeatsBlock(\n",
    "      input_size=INPUT_SIZE,\n",
    "      theta_size=THETA_SIZE,\n",
    "      horizon=HORIZON,\n",
    "      n_neurons=N_NEURONS,\n",
    "      n_layers=N_LAYERS,\n",
    "      name=f\"NBeatsBlock_{i}\"\n",
    "  )(residuals) # pass it in residuals (the backcast)\n",
    "\n",
    "  # 6. Create the double residual stacking\n",
    "  residuals = layers.subtract([residuals, backcast], name=f\"subtract_{i}\") \n",
    "  forecast = layers.add([forecast, block_forecast], name=f\"add_{i}\")\n",
    "\n",
    "# 7. Put the stack model together\n",
    "model_7 = tf.keras.Model(inputs=stack_input, \n",
    "                         outputs=forecast, \n",
    "                         name=\"model_7_N-BEATS\")\n",
    "\n",
    "# 8. Compile with MAE loss and Adam optimizer\n",
    "model_7.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                metrics=[\"mae\", \"mse\"])\n",
    "\n",
    "# 9. Fit the model with EarlyStopping and ReduceLROnPlateau callbacks\n",
    "model_7.fit(train_dataset,\n",
    "            epochs=N_EPOCHS,\n",
    "            validation_data=test_dataset,\n",
    "            verbose=0, # prevent large amounts of training outputs\n",
    "            # callbacks=[create_model_checkpoint(model_name=stack_model.name)] # saving model every epoch consumes far too much time\n",
    "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=200, restore_best_weights=True),\n",
    "                      tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=100, verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_pred):\n",
    "\n",
    "  y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "  y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "\n",
    "  mae = tf.keras.metrics.mean_absolute_error(y_true, y_pred)\n",
    "  mse = tf.keras.metrics.mean_squared_error(y_true, y_pred) \n",
    "  rmse = tf.sqrt(mse)\n",
    "  mape = tf.keras.metrics.mean_absolute_percentage_error(y_true, y_pred)\n",
    "  #mase = mean_absolute_scaled_error(y_true, y_pred)\n",
    "  \n",
    "  return {\"mae\": mae.numpy(),\n",
    "          \"mse\": mse.numpy(),\n",
    "          \"rmse\": rmse.numpy(),\n",
    "          \"mape\": mape.numpy(),\n",
    "         # \"mase\": mase.numpy()\n",
    "          }\n",
    "\n",
    "def make_preds(model, input_data):\n",
    "  forecast = model.predict(input_data)\n",
    "  return tf.squeeze(forecast) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 245ms/step - loss: 581.9904 - mae: 581.9904 - mse: 1133993.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mae': 581.99036, 'mse': 1133993.6, 'rmse': 1064.8914, 'mape': 2.705088}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_preds = make_preds(model_7, test_dataset)\n",
    "model_7_preds[:10]\n",
    "\n",
    "model_7.evaluate(test_dataset)\n",
    "model_7_results = evaluate_preds(y_true=y_test, y_pred=model_7_preds)\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 8: Creating an ensemble\n",
    "\n",
    "def get_ensemble_models(horizon=HORIZON, \n",
    "                        train_data=train_dataset,\n",
    "                        test_data=test_dataset,\n",
    "                        num_iter=10, \n",
    "                        num_epochs=100, \n",
    "                        loss_fns=[\"mae\", \"mse\", \"mape\"]):\n",
    "  \"\"\"\n",
    "  Returns a list of num_iter models each trained on MAE, MSE and MAPE loss.\n",
    "\n",
    "  For example, if num_iter=10, a list of 30 trained models will be returned:\n",
    "  10 * len([\"mae\", \"mse\", \"mape\"]).\n",
    "  \"\"\"\n",
    "  # Make empty list for trained ensemble models\n",
    "  ensemble_models = []\n",
    "\n",
    "  # Create num_iter number of models per loss function\n",
    "  for i in range(num_iter):\n",
    "    # Build and fit a new model with a different loss function\n",
    "    for loss_function in loss_fns:\n",
    "      print(f\"Optimizing model by reducing: {loss_function} for {num_epochs} epochs, model number: {i}\")\n",
    "\n",
    "      # Construct a simple model (similar to model_1)\n",
    "      model = tf.keras.Sequential([\n",
    "        # Initialize layers with normal (Gaussian) distribution so we can use the models for prediction\n",
    "        # interval estimation later: https://www.tensorflow.org/api_docs/python/tf/keras/initializers/HeNormal\n",
    "        layers.Dense(128, kernel_initializer=\"he_normal\", activation=\"relu\"), \n",
    "        layers.Dense(128, kernel_initializer=\"he_normal\", activation=\"relu\"),\n",
    "        layers.Dense(HORIZON)                                 \n",
    "      ])\n",
    "\n",
    "      # Compile simple model with current loss function\n",
    "      model.compile(loss=loss_function,\n",
    "                    optimizer=tf.keras.optimizers.Adam(),\n",
    "                    metrics=[\"mae\", \"mse\"])\n",
    "      \n",
    "      # Fit model\n",
    "      model.fit(train_data,\n",
    "                epochs=num_epochs,\n",
    "                verbose=0,\n",
    "                validation_data=test_data,\n",
    "                # Add callbacks to prevent training from going/stalling for too long\n",
    "                callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                            patience=200,\n",
    "                                                            restore_best_weights=True),\n",
    "                           tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                                                patience=100,\n",
    "                                                                verbose=1)])\n",
    "      \n",
    "      # Append fitted model to list of ensemble models\n",
    "      ensemble_models.append(model)\n",
    "\n",
    "  return ensemble_models # list of trained models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get list of trained ensemble models\n",
    "ensemble_models = get_ensemble_models(num_iter=5,\n",
    "                                      num_epochs=10) # cut to decrease train time 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ensemble_preds(ensemble_models, data):\n",
    "  ensemble_preds = []\n",
    "  for model in ensemble_models:\n",
    "    preds = model.predict(data) # make predictions with current ensemble model\n",
    "    ensemble_preds.append(preds)\n",
    "  return tf.constant(tf.squeeze(ensemble_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_preds = make_ensemble_preds(ensemble_models=ensemble_models, data=test_dataset)\n",
    "ensemble_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 837.9614, 'mse': 2404642.0, 'rmse': 1550.6908, 'mape': 3.7575662}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "ensemble_results = evaluate_preds(y_true=y_test,\n",
    "    y_pred=np.median(ensemble_preds, axis=0)) # take the median across all ensemble predictions\n",
    "ensemble_results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "895f5999c4df1ea8154f93b7f1a5ced7e9a0ab5a8b85031e86bae67bc804f9a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('3.9.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
